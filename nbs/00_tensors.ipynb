{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensors\n",
    "\n",
    "> A lovely way to display Pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from click import style\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import test_eq\n",
    "\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# |exporti\n",
    "class __PrinterOptions(object):\n",
    "    precision: int = 3\n",
    "    threshold_max: int = 3 # .abs() larger than 1e3 -> Sci mode\n",
    "    threshold_min: int = -4 # .abs() smaller that 1e-4 -> Sci mode\n",
    "    sci_mode: Optional[bool] = None # None = auto. Otherwise, force sci mode.\n",
    "    color: bool = True # Now in color\n",
    "\n",
    "PRINT_OPTS = __PrinterOptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "# |exporti\n",
    "# Do we want this float in decimal or scientific mode?\n",
    "def sci_mode(f: float):\n",
    "    return (abs(f) < 10**(PRINT_OPTS.threshold_min) or\n",
    "            abs(f) > 10**PRINT_OPTS.threshold_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "\n",
    "test_eq(sci_mode(1.), False)\n",
    "test_eq(sci_mode(0.00001), True)\n",
    "test_eq(sci_mode(10000000), True)\n",
    "\n",
    "# It would be fine either way, both `e` and `f` formats handle those.\n",
    "test_eq(sci_mode(float('nan')), False)\n",
    "test_eq(sci_mode(float('inf')), True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{:.4e}', '1.2300e+00')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |hide\n",
    "\n",
    "# What's happening in the cell below\n",
    "fmt = f\"{{:.{4}{'e'}}}\"\n",
    "fmt, fmt.format(1.23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly better way to print `float` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "# Convert a tensor into a string.\n",
    "# This only looks good for small tensors, which is how it's intended to be used.\n",
    "def tensor_str(t: torch.Tensor):\n",
    "    if t.dim() == 0:\n",
    "        v = t.item()\n",
    "        if t.is_floating_point():\n",
    "            if not t.is_nonzero():\n",
    "                return \"0.\"\n",
    "\n",
    "            sci = (PRINT_OPTS.sci_mode or\n",
    "                    (PRINT_OPTS.sci_mode is None and sci_mode(v)))\n",
    "\n",
    "            # The f-string will generate something like \"{.4f}\", which is used\n",
    "            # to format the value.\n",
    "            return f\"{{:.{PRINT_OPTS.precision}{'e' if sci else 'f'}}}\".format(v)\n",
    "        else:\n",
    "            return '{}'.format(v) # Should we use sci mode for large ints too?\n",
    "    else:\n",
    "        slices = [tensor_str(t[i]) for i in range(0, t.size(0))]\n",
    "        return '[' + \", \".join(slices) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "torch.manual_seed(42)\n",
    "randoms = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "t = randoms[:12].clone()\n",
    "\n",
    "t[0] *= 10000\n",
    "t[1] /= 10000\n",
    "t[3] = float('inf')\n",
    "t[4] = float('-inf')\n",
    "t[5] = float('nan')\n",
    "t = t.reshape((2,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[1.927e+04, 0.000, 0.901, inf, -inf, nan], [-0.043, -1.605, -0.752, 1.649, -0.392, -1.404]]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_str(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(tensor_str(t), '[[1.927e+04, 0.000, 0.901, inf, -inf, nan], [-0.043, -1.605, -0.752, 1.649, -0.392, -1.404]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "# |hide\n",
    "def space_join(lst):\n",
    "    # Join non-empty list elements into a space-sepaeated string\n",
    "    return \" \".join( [ l for l in lst if l] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(space_join([\"Hello\", None, \"World\"]), 'Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHello, world!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "print(style(\"Hello, world!\", fg=\"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@torch.no_grad()\n",
    "def lovely(t: torch.Tensor, verbose=False, plain=False):\n",
    "    if plain:\n",
    "        return torch._tensor_str._tensor_str(t, indent=0)\n",
    "\n",
    "    tname = \"tensor\" if type(t) in [torch.Tensor, torch.nn.Parameter] else type(t).__name__\n",
    "\n",
    "    grad_fn = \"grad_fn\" if t.grad_fn else None\n",
    "    # All tensors along the compute path actually have required_grad=True. Torch __repr__ just dones not show it.\n",
    "    grad = \"grad\" if not t.grad_fn and t.requires_grad else None\n",
    "\n",
    "    shape = str(list(t.shape))\n",
    "\n",
    "    zeros = style(\"all_zeros\", (127, 127, 127)) if not t.count_nonzero() else None\n",
    "    pinf = style(\"+inf!\", \"red\") if t.isposinf().any() else None\n",
    "    ninf = style(\"-inf!\", \"red\") if t.isneginf().any() else None\n",
    "    nan = style(\"nan!\", \"red\") if t.isnan().any() else None\n",
    "\n",
    "    attention = space_join([zeros,pinf,ninf,nan])\n",
    "\n",
    "    x, summary = \"\", \"\"\n",
    "    if not zeros:\n",
    "        x = \"x=\" + (tensor_str(t) if t.numel() <= 10 else \"...\")\n",
    "\n",
    "        # Make sure it's float32. Also, we calculate stats on good values only.\n",
    "        ft = t.float()[  torch.isfinite(t) ]\n",
    "\n",
    "        minmax = f\"x∈[{tensor_str(ft.min())}, {tensor_str(ft.max())}]\" if t.numel() > 2 and ft.numel() > 2 else None\n",
    "        meanstd = f\"μ={tensor_str(ft.mean())} σ={tensor_str(ft.std())}\" if t.numel() >= 2 and ft.numel() >= 2 else None\n",
    "        numel = f\"n={t.numel()}\" if t.numel() > 5 else None\n",
    "\n",
    "        summary = space_join([numel, minmax, meanstd])\n",
    "\n",
    "    dtnames = { torch.float32: \"\",\n",
    "                torch.float16: \"fp16\",\n",
    "                torch.float64: \"fp64\",\n",
    "                torch.uint8: \"u8\",\n",
    "                torch.int32: \"i32\",\n",
    "             }\n",
    "\n",
    "    dtype = dtnames[t.dtype] if t.dtype in dtnames else str(t.dtype)[6:]\n",
    "    dev = str(t.device) if t.device.type != \"cpu\" else None\n",
    "\n",
    "    res = tname + space_join([shape,summary,dtype,grad,grad_fn,dev,attention]) \n",
    "    return res + (\"\\nx=\" + torch._tensor_str._tensor_str(t, indent=2) if verbose else \" \"+x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would be _lovely_ if you could see all the important tensor stats too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[] x=1.927\n",
      "tensor[2] μ=1.707 σ=0.311 x=[1.927, 1.487]\n",
      "tensor[2, 3] n=6 x∈[-2.106, 1.927] μ=0.276 σ=1.594 x=[[1.927, 1.487, 0.901], [-2.106, 0.678, -1.235]]\n",
      "tensor[11] n=11 x∈[-2.106, 1.927] μ=0.046 σ=1.384 x=...\n"
     ]
    }
   ],
   "source": [
    "t0,t1,t2,t3 = randoms[0], randoms[:2], randoms[:6].view(2, 3), randoms[:11]\n",
    "\n",
    "print(lovely(t0))\n",
    "print(lovely(t1))\n",
    "print(lovely(t2)) # More than 2 elements -> show statistics\n",
    "print(lovely(t3)) # More than 10 -> suppress data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(lovely(t0), \"tensor[] x=1.927\")\n",
    "test_eq(lovely(t1), \"tensor[2] μ=1.707 σ=0.311 x=[1.927, 1.487]\")\n",
    "test_eq(lovely(t2), \"tensor[2, 3] n=6 x∈[-2.106, 1.927] μ=0.276 σ=1.594 x=[[1.927, 1.487, 0.901], [-2.106, 0.678, -1.235]]\")\n",
    "test_eq(lovely(t3), \"tensor[11] n=11 x∈[-2.106, 1.927] μ=0.046 σ=1.384 x=...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[] grad x=1.000\n",
      "tensor[] grad_fn x=2.000\n"
     ]
    }
   ],
   "source": [
    "grad = torch.tensor(1., requires_grad=True)\n",
    "print(lovely(grad)); print(lovely(grad+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "test_eq(lovely(grad), \"tensor[] grad x=1.000\")\n",
    "test_eq(lovely(grad+1), \"tensor[] grad_fn x=2.000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[] cuda:0 x=1.000\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(lovely(torch.tensor(1., device=torch.device(\"cuda:0\"))))\n",
    "    test_eq(lovely(torch.tensor(1., device=torch.device(\"cuda:0\"))), \"tensor[] cuda:0 x=1.000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TestClass[1] x=[1.000]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestClass(torch.Tensor): pass\n",
    "\n",
    "lovely(TestClass([1.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have __any__ floating point nasties? Is the tensor __all__ zeros?\n",
    "\n",
    "> Statistics and range are calculated on good values only, if there are at lest 3 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[2, 6] n=12 x∈[-1.605, 1.927e+04] μ=2.141e+03 σ=6.423e+03 \u001b[31m+inf!\u001b[0m \u001b[31m-inf!\u001b[0m \u001b[31mnan!\u001b[0m x=...\n",
      "tensor[12] \u001b[38;2;127;127;127mall_zeros\u001b[0m \n",
      "tensor[11] n=11 \u001b[31mnan!\u001b[0m x=...\n"
     ]
    }
   ],
   "source": [
    "print(lovely(t))\n",
    "print(lovely(torch.zeros(12)))\n",
    "print(lovely(torch.tensor([float(\"nan\")]*11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose:\n",
      "tensor[2, 6] n=12 x∈[-1.605, 1.927e+04] μ=2.141e+03 σ=6.423e+03 \u001b[31m+inf!\u001b[0m \u001b[31m-inf!\u001b[0m \u001b[31mnan!\u001b[0m\n",
      "x=[[ 1.9269e+04,  1.4873e-04,  9.0072e-01,         inf,        -inf,         nan],\n",
      "   [-4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00, -3.9248e-01, -1.4036e+00]]\n",
      "\n",
      "Plain:\n",
      "[[ 1.9269e+04,  1.4873e-04,  9.0072e-01,         inf,        -inf,         nan],\n",
      " [-4.3067e-02, -1.6047e+00, -7.5214e-01,  1.6487e+00, -3.9248e-01, -1.4036e+00]]\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(linewidth=120)\n",
    "\n",
    "print(\"Verbose:\")\n",
    "print(lovely(t, verbose=True))\n",
    "print(\"\\nPlain:\")\n",
    "print(lovely(t, plain=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would be lovely if we did not have to call the function explicitly.\n",
    "\n",
    "Let's monkey-patch `torch.Tensor` itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "# |hide\n",
    "\n",
    "def styled_tensor(t: torch.Tensor, tensor_contents, style):\n",
    "    assert style in [\"plain\", \"verbose\"]\n",
    "    t = tensor_contents if tensor_contents is not None else t\n",
    "    t = t.view(t.shape)\n",
    "    setattr(t, \"_lovely_\" + style, True)\n",
    "    return t\n",
    "\n",
    "# Keep an esiy way to get the standard behavior.\n",
    "@property\n",
    "def plain_tensor(t: torch.Tensor, *, tensor_contents=None):\n",
    "    return styled_tensor(t, tensor_contents, \"plain\")\n",
    "\n",
    "# And a verbose option for a good measure.\n",
    "@property\n",
    "def verbose_tensor(t: torch.Tensor, *, tensor_contents=None):\n",
    "    return styled_tensor(t, tensor_contents, \"verbose\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exporti\n",
    "# |hide\n",
    "def lovely_repr(t: torch.Tensor, *, tensor_contents=None):\n",
    "    plain = hasattr(t, \"_lovely_plain\") and t._lovely_plain\n",
    "    verbose = hasattr(t, \"_lovely_verbose\") and t._lovely_verbose\n",
    "\n",
    "    return lovely(t, plain=plain, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def monkey_patch(cls=torch.Tensor):\n",
    "    \"Monkey-patch lovely features into `cls`\" \n",
    "    cls.__repr__ = lovely_repr\n",
    "    cls.plain = plain_tensor\n",
    "    cls.verbose = verbose_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |skip\n",
    "monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[2, 6] n=12 x∈[-1.605, 1.927e+04] μ=2.141e+03 σ=6.423e+03 \u001b[31m+inf!\u001b[0m \u001b[31m-inf!\u001b[0m \u001b[31mnan!\u001b[0m x=..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
